# LLM Configuration
LLM_MODEL_PATH=models/gemma-3-1b-it-q4_0.gguf
LLM_CONTEXT_SIZE=2048
LLM_N_GPU_LAYERS=0  # Set to 0 for CPU, or number of layers to offload to GPU
LLM_MODEL_TYPE=gemma  # Model type (gemma, llama, etc.)

# Vector Database
VECTOR_DB_PATH=./data/vector_db
VECTOR_DB_TYPE=chroma  # or 'faiss'

# Embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2  # or other sentence-transformers model

# Document Processing
DOCUMENTS_DIR=./data/documents
PROCESSED_DIR=./data/processed

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/llm_service.log

# Optional: HuggingFace Hub (if using HF models)
# HUGGINGFACE_HUB_TOKEN=your_token_here
